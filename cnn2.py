# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12ZLuxQ-P1PlpW9j8CNQbXYTYZwewhepk
"""

"""
A test case

"""

def model():
  model = tf.keras.Sequential([
    #1st Conv1D
      tf.keras.layers.Conv1D(8, 1, strides=1, 
                            activation='relu', input_shape=(3750,1)),
      tf.keras.layers.BatchNormalization(),
      tf.keras.layers.MaxPooling1D(pool_size=2,strides=2),
      tf.keras.layers.Dropout(0.2),
      #2nd Conv1D
      tf.keras.layers.Conv1D(16, 3, strides=1,
                            activation='relu'),
      tf.keras.layers.BatchNormalization(),
      tf.keras.layers.MaxPooling1D(pool_size=2,strides=2),
      tf.keras.layers.Dropout(0.2),
      #3rd Conv1D
      tf.keras.layers.Conv1D(32, 3, strides=1,
                            activation='relu'),
      tf.keras.layers.BatchNormalization(),
      tf.keras.layers.MaxPooling1D(pool_size=2,strides=2),
      tf.keras.layers.Dropout(0.2),
      #4th Conv1D
      tf.keras.layers.Conv1D(64, 3, strides=1,
                            activation='relu'),
      tf.keras.layers.BatchNormalization(),
      tf.keras.layers.MaxPooling1D(pool_size=2,strides=2),
      tf.keras.layers.Dropout(0.2),
      #5th Conv1D
      tf.keras.layers.Conv1D(16, 1, strides=1,
                            activation='relu'),
      tf.keras.layers.BatchNormalization(),
      #Full connection layer
      tf.keras.layers.Flatten(),
      #tf.keras.layers.LSTM(50, stateful=True, return_sequences=True),
      #tf.keras.layers.LSTM(10, stateful=True),
      tf.keras.layers.Dense(64, activation='relu'),
      tf.keras.layers.BatchNormalization(),
      tf.keras.layers.Dropout(0.2),
      tf.keras.layers.Dense(1, activation = 'sigmoid')
  ])
  return model